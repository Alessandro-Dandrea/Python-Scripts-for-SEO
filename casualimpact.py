# -*- coding: utf-8 -*-
"""CasualImpact.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NVcltC1kT2_E4EbbtnPamGeL1tnjgV3B
"""

!pip install pycausalimpact
!pip install git+https://github.com/joshcarty/google-searchconsole

import numpy as np
import pandas as pd
from statsmodels.tsa.arima_process import ArmaProcess
from causalimpact import CausalImpact

# Open the CSV file with the data to analyze (we have only dates here)
# >>>Remove CTR Column!!<<<

data = pd.read_csv('dataset.csv', # Update the string here to change the file. Upload the file first.
                 header=0,
                 encoding="utf-8",
                 index_col='Date') 
data= data.loc[~data.index.duplicated(), :] #This is for removing duplicated label in index. Still don't know why there's duplicated labels.
print("we have a total of:", len(data), " samples")

data.head()

data.sort_values(by=['Date'], inplace=True, ascending=True)
data[['Clicks']].plot()

print(np.min(data.index.values))
print(np.max(data.index.values))

pre_period = ["2022-02-16", "2022-05-18"] # before changings
post_period = ["2022-05-19", "2022-08-19"]

#ci = CausalImpact(data.iloc[:, 0], pre_period, post_period, nseasons=[{'period': 52}])
ci = CausalImpact(data['Clicks'], pre_period, post_period) # here we might add seasonality as in the example above

print(ci.summary())
ci.plot()
print(ci.summary(output='report'))